{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of  v4_cotton plat disease prediction.ipynb","provenance":[{"file_id":"1FKlVBwSTRVn-4PnkESvt3WIjCao9VzH0","timestamp":1615815714136}],"collapsed_sections":[],"history_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SP_m5pBa4F5F"},"source":["### v4, epochs 500"]},{"cell_type":"markdown","metadata":{"id":"0v994vCS2CBq"},"source":["## Project: ðŸŒ¿Cotton Plant Disease Prediction & Get Cure App"]},{"cell_type":"code","metadata":{"id":"JPpFXWvdZ8Yw","executionInfo":{"status":"ok","timestamp":1615815452142,"user_tz":-330,"elapsed":5050,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["#import libraries\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","\n","# for accuracy and loss graph\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtT0wL4PaHsT","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1615815452152,"user_tz":-330,"elapsed":5037,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}},"outputId":"d5b4beb5-7999-4f2a-e0cf-d70e8a3c922f"},"source":["keras.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.3'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SE7fx44yaJBe","executionInfo":{"status":"ok","timestamp":1615815452154,"user_tz":-330,"elapsed":5032,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["train_data_path = \"/content/drive/My Drive/My ML Project /DL Project/CNN/cotton plant disease prediction/data/train\"\n","validation_data_path = \"/content/drive/My Drive/My ML Project /DL Project/CNN/cotton plant disease prediction/data/val\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQkoR7xGjXdO","executionInfo":{"status":"ok","timestamp":1615815452156,"user_tz":-330,"elapsed":5029,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# show augmented images\n","def plotImages(images_arr):\n","    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n","    axes = axes.flatten()\n","    for img, ax in zip(images_arr, axes):\n","        ax.imshow(img)\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6G1wOvyaaWF","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"error","timestamp":1615815452176,"user_tz":-330,"elapsed":5034,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}},"outputId":"312c9378-9553-4c15-9633-703fc8b122cc"},"source":["# this is the augmentation configuration we will use for training\n","# It generate more images using below parameters\n","training_datagen = ImageDataGenerator(rescale=1./255,\n","                                      rotation_range=40,\n","                                      width_shift_range=0.2,\n","                                      height_shift_range=0.2,\n","                                      shear_range=0.2,\n","                                      zoom_range=0.2,\n","                                      horizontal_flip=True,\n","                                      fill_mode='nearest')\n","\n","# this is a generator that will read pictures found in\n","# at train_data_path, and indefinitely generate\n","# batches of augmented image data\n","training_data = training_datagen.flow_from_directory(train_data_path, # this is the target directory\n","                                      target_size=(150, 150), # all images will be resized to 150x150\n","                                      batch_size=32,\n","                                      class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-245ce33360f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                       \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# all images will be resized to 150x150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                       class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/My ML Project /DL Project/CNN/cotton plant disease prediction/data/train'"]}]},{"cell_type":"code","metadata":{"id":"UNL51xLzaa03","executionInfo":{"status":"aborted","timestamp":1615815452157,"user_tz":-330,"elapsed":5002,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["training_data.class_indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lx85AXqWm1lg","executionInfo":{"status":"aborted","timestamp":1615815452159,"user_tz":-330,"elapsed":4996,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsEWPhERacv-","executionInfo":{"status":"aborted","timestamp":1615815452161,"user_tz":-330,"elapsed":4984,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# this is the augmentation configuration we will use for validation:\n","# only rescaling\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# this is a similar generator, for validation data\n","valid_data = valid_datagen.flow_from_directory(validation_data_path,\n","                                  target_size=(150,150),\n","                                  batch_size=32,\n","                                  class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBsy7X2ojfB3","executionInfo":{"status":"aborted","timestamp":1615815452162,"user_tz":-330,"elapsed":4970,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# showing augmented images\n","images = [training_data[0][0][0] for i in range(5)]\n","plotImages(images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNgoqdNfaiWu","executionInfo":{"status":"aborted","timestamp":1615815452164,"user_tz":-330,"elapsed":4966,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# save best model using vall accuracy\n","model_path = '/content/drive/My Drive/My ML Project /DL Project/CNN/cotton plant disease prediction/v4_pred_cott_dis.h5'\n","checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBibEQsHazjW","executionInfo":{"status":"aborted","timestamp":1615815452166,"user_tz":-330,"elapsed":4963,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["\n","#Building cnn model\n","cnn_model = keras.models.Sequential([\n","                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n","                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n","                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n","                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n","                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n","\n","                                    keras.layers.Dropout(0.5),                                                                        \n","                                    keras.layers.Flatten(), # neural network beulding\n","                                    keras.layers.Dense(units=128, activation='relu'), # input layers\n","                                    keras.layers.Dropout(0.1),                                    \n","                                    keras.layers.Dense(units=256, activation='relu'),                                    \n","                                    keras.layers.Dropout(0.25),                                    \n","                                    keras.layers.Dense(units=4, activation='softmax') # output layer\n","])\n","\n","\n","# compile cnn model\n","cnn_model.compile(optimizer = Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Atni-D1q1-T","executionInfo":{"status":"aborted","timestamp":1615815452167,"user_tz":-330,"elapsed":4950,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["cnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iq1ocdyEozOz","executionInfo":{"status":"aborted","timestamp":1615815452169,"user_tz":-330,"elapsed":4938,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# train cnn model\n","history = cnn_model.fit(training_data, \n","                          epochs=500, \n","                          verbose=1, \n","                          validation_data= valid_data,\n","                          callbacks=callbacks_list) # time start 16.06"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdRtlOuxvY43","executionInfo":{"status":"aborted","timestamp":1615815452170,"user_tz":-330,"elapsed":4933,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["model_path2 = '/content/drive/My Drive/My ML Project /DL Project/CNN/cotton plant disease prediction/v4_1_pred_cott_dis.h5'\n","cnn_model.save(model_path2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F2ao39xq1O5Q","executionInfo":{"status":"aborted","timestamp":1615815452172,"user_tz":-330,"elapsed":4923,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9h9XsooU1dEx","executionInfo":{"status":"aborted","timestamp":1615815452174,"user_tz":-330,"elapsed":4914,"user":{"displayName":"LAN_15","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVNOkN_Mqu9GZUkKqU1KWpP0dgQzVaq2e5pQtEhNo=s64","userId":"02635693040810268402"}}},"source":["history.history"],"execution_count":null,"outputs":[]}]}